{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_for_conv_image_on_encoding():\n",
    "    return ret\n",
    "\n",
    "\n",
    "def conv_step(input_img, kernel, out_dim, strides=[1,1,1,1]):\n",
    "    conv_filter1 = tf.Variable(tf.truncated_normal([kernel, kernel, int(input_img.get_shape()[-1]), out_dim], stddev=0.5, seed=1)) #weight dimensions.\n",
    "    conv1 = tf.nn.conv2d(input=input_img, filter=conv_filter1, strides=strides, padding=\"VALID\")\n",
    "    \n",
    "    conv_filter2 = tf.Variable(tf.truncated_normal([kernel, kernel, int(conv1.get_shape()[-1]), out_dim], stddev=0.5))\n",
    "    conv2 = tf.nn.conv2d(input=conv1, filter=conv_filter2, strides=strides, padding=\"VALID\")\n",
    "    \n",
    "    print(\"conv1 : \", conv1)\n",
    "    print(\"conv2 : \", conv2)\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    return conv2\n",
    "\n",
    "def segmentation(input, kernel, out_dim, strides=[1,1,1,1]):\n",
    "    conv_filter1 = tf.Variable(tf.truncated_normal([kernel, kernel, int(input_img.get_shape()[-1]), out_dim], stddev=0.5, seed=1)) #weight dimensions.\n",
    "    conv1 = tf.nn.conv2d(input=input_img, filter=conv_filter1, strides=strides, padding=\"VALID\")\n",
    "    \n",
    "    print(\"conv1 : \", conv1)\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    return conv2\n",
    "'''\n",
    "def up_conv(input_img, kernel, out_dim, strides=[1,1,1,1]):\n",
    "    up_convolution_filter = tf.Variable(tf.truncated_normal([kernel, kernel, int(input_img.get_shape()[-1]), out_dim], stddev=0.5))\n",
    "    output_shape = [tf.shape(input_img)[0], int(input_img.get_shape()[1])*2, int(input_img.get_shape()[2]*2),out_dim]\n",
    "    upsample = tf.nn.conv2d_transpose(value=input_img, filter=up_convolution_filter, output_shape=tf.stack(output_shape),strides=strides, padding=\"SAME\")\n",
    "    \n",
    "    print(\"up-conv : \", upsample)\n",
    "    return upsample\n",
    "'''\n",
    "def up_conv(input_img, kernel, out_dim, strides=[2,2]):\n",
    "    up_convolution_filter = tf.Variable(tf.truncated_normal([kernel, kernel, int(input_img.get_shape()[-1]), out_dim], stddev=0.5))\n",
    "    upsample = tf.layers.conv2d_transpose(input_img, filters=out_dim, kernel_size=(2,2), strides=strides, padding=\"SAME\")\n",
    "    \n",
    "    print(\"up-conv : \", upsample)\n",
    "    upsample = tf.nn.relu(upsample)\n",
    "    return upsample\n",
    "    \n",
    "def max_pooling(after_conv):\n",
    "    pooling = tf.nn.max_pool(after_conv, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    \n",
    "    return pooling\n",
    "\n",
    "def get_crop_dim(conv_out, decoding_out):\n",
    "    \n",
    "    #print(decoding_out.get_shape())\n",
    "    \n",
    "    orig_h = int(conv_out.shape[1])\n",
    "    orig_w = int(conv_out.shape[2])\n",
    "    \n",
    "    crop_size_h = int(decoding_out.get_shape()[1])\n",
    "    crop_size_w = int(decoding_out.get_shape()[2])\n",
    "    \n",
    "    offset_h = (orig_h - crop_size_h) / 2\n",
    "    offset_w = (orig_w - crop_size_w) / 2\n",
    "    \n",
    "    height = crop_size_h\n",
    "    width = crop_size_w\n",
    "    \n",
    "    #print(orig_h, orig_w, offset_h, offset_w)\n",
    "    \n",
    "    return int(offset_h), int(offset_w), int(height), int(width)\n",
    "\n",
    "def cropping_concat(encoding_out=None, decoding_out=None):\n",
    "    crop_dim = get_crop_dim(encoding_out, decoding_out)\n",
    "    crop = tf.image.crop_to_bounding_box(encoding_out, crop_dim[0],crop_dim[1],crop_dim[2],crop_dim[3])\n",
    "    \n",
    "    concat = tf.concat([crop, decoding_out],-1)\n",
    "    return concat\n",
    "    \n",
    "def encoding_step():\n",
    "    return enc\n",
    "def decoding_step():\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 572, 572, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_dim = tf.placeholder(tf.float32, shape=[None,572,572,3])\n",
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 :  Tensor(\"Conv2D:0\", shape=(?, 570, 570, 64), dtype=float32)\n",
      "conv2 :  Tensor(\"Conv2D_1:0\", shape=(?, 568, 568, 64), dtype=float32)\n",
      "1_conv_layer_test :  Tensor(\"Relu:0\", shape=(?, 568, 568, 64), dtype=float32)\n",
      "1_pooling_layer_test :  Tensor(\"MaxPool:0\", shape=(?, 284, 284, 64), dtype=float32)\n",
      "conv1 :  Tensor(\"Conv2D_2:0\", shape=(?, 282, 282, 128), dtype=float32)\n",
      "conv2 :  Tensor(\"Conv2D_3:0\", shape=(?, 280, 280, 128), dtype=float32)\n",
      "2_conv_layer_test :  Tensor(\"Relu_1:0\", shape=(?, 280, 280, 128), dtype=float32)\n",
      "2_pooling_layer_test :  Tensor(\"MaxPool_1:0\", shape=(?, 140, 140, 128), dtype=float32)\n",
      "conv1 :  Tensor(\"Conv2D_4:0\", shape=(?, 138, 138, 256), dtype=float32)\n",
      "conv2 :  Tensor(\"Conv2D_5:0\", shape=(?, 136, 136, 256), dtype=float32)\n",
      "3_conv_layer_test :  Tensor(\"Relu_2:0\", shape=(?, 136, 136, 256), dtype=float32)\n",
      "3_pooling_layer_test :  Tensor(\"MaxPool_2:0\", shape=(?, 68, 68, 256), dtype=float32)\n",
      "conv1 :  Tensor(\"Conv2D_6:0\", shape=(?, 66, 66, 512), dtype=float32)\n",
      "conv2 :  Tensor(\"Conv2D_7:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "3_conv_layer_test :  Tensor(\"Relu_3:0\", shape=(?, 64, 64, 512), dtype=float32)\n",
      "3_pooling_layer_test :  Tensor(\"MaxPool_3:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "conv1 :  Tensor(\"Conv2D_8:0\", shape=(?, 30, 30, 1024), dtype=float32)\n",
      "conv2 :  Tensor(\"Conv2D_9:0\", shape=(?, 28, 28, 1024), dtype=float32)\n",
      "extends :  Tensor(\"Relu_4:0\", shape=(?, 28, 28, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# conv1 + max1\n",
    "conv_1_output = conv_step(input_dim, 3, 64)\n",
    "print(\"1_conv_layer_test : \", conv_1_output)\n",
    "pool_1_output = max_pooling(conv_1_output)\n",
    "print(\"1_pooling_layer_test : \", pool_1_output)\n",
    "\n",
    "#conv2 + max2\n",
    "conv_2_output = conv_step(pool_1_output, 3, 64*2)\n",
    "print(\"2_conv_layer_test : \", conv_2_output)\n",
    "pool_2_output = max_pooling(conv_2_output)\n",
    "print(\"2_pooling_layer_test : \", pool_2_output)\n",
    "\n",
    "#conv3 + max3\n",
    "conv_3_output = conv_step(pool_2_output, 3, 64*4)\n",
    "print(\"3_conv_layer_test : \", conv_3_output)\n",
    "pool_3_output = max_pooling(conv_3_output)\n",
    "print(\"3_pooling_layer_test : \", pool_3_output)\n",
    "\n",
    "#conv4 + max4\n",
    "conv_4_output = conv_step(pool_3_output, 3, 64*8)\n",
    "print(\"3_conv_layer_test : \", conv_4_output)\n",
    "pool_4_output = max_pooling(conv_4_output)\n",
    "print(\"3_pooling_layer_test : \", pool_4_output)\n",
    "\n",
    "#extends\n",
    "extend = conv_step(pool_4_output, 3, 64*16)\n",
    "print(\"extends : \", extend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up-conv :  Tensor(\"conv2d_transpose/BiasAdd:0\", shape=(?, 56, 56, 512), dtype=float32)\n",
      "concat_1 :  Tensor(\"concat:0\", shape=(?, 56, 56, 1024), dtype=float32)\n",
      "conv1 :  Tensor(\"Conv2D_10:0\", shape=(?, 54, 54, 256), dtype=float32)\n",
      "conv2 :  Tensor(\"Conv2D_11:0\", shape=(?, 52, 52, 256), dtype=float32)\n",
      "5_conv_layer_test :  Tensor(\"Relu_6:0\", shape=(?, 52, 52, 256), dtype=float32)\n",
      "up-conv :  Tensor(\"conv2d_transpose_1/BiasAdd:0\", shape=(?, 104, 104, 256), dtype=float32)\n",
      "concat_2 :  Tensor(\"concat_1:0\", shape=(?, 104, 104, 512), dtype=float32)\n",
      "conv1 :  Tensor(\"Conv2D_12:0\", shape=(?, 102, 102, 128), dtype=float32)\n",
      "conv2 :  Tensor(\"Conv2D_13:0\", shape=(?, 100, 100, 128), dtype=float32)\n",
      "6_conv_layer_test :  Tensor(\"Relu_8:0\", shape=(?, 100, 100, 128), dtype=float32)\n",
      "up-conv :  Tensor(\"conv2d_transpose_2/BiasAdd:0\", shape=(?, 200, 200, 128), dtype=float32)\n",
      "concat_3 :  Tensor(\"concat_2:0\", shape=(?, 200, 200, 256), dtype=float32)\n",
      "conv1 :  Tensor(\"Conv2D_14:0\", shape=(?, 198, 198, 64), dtype=float32)\n",
      "conv2 :  Tensor(\"Conv2D_15:0\", shape=(?, 196, 196, 64), dtype=float32)\n",
      "7_conv_layer_test :  Tensor(\"Relu_8:0\", shape=(?, 100, 100, 128), dtype=float32)\n",
      "up-conv :  Tensor(\"conv2d_transpose_3/BiasAdd:0\", shape=(?, 392, 392, 64), dtype=float32)\n",
      "concat_4 :  Tensor(\"concat_3:0\", shape=(?, 392, 392, 128), dtype=float32)\n",
      "conv1 :  Tensor(\"Conv2D_16:0\", shape=(?, 390, 390, 64), dtype=float32)\n",
      "conv2 :  Tensor(\"Conv2D_17:0\", shape=(?, 388, 388, 64), dtype=float32)\n",
      "8_conv_layer_test :  Tensor(\"Relu_12:0\", shape=(?, 388, 388, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#upsample and concat\n",
    "up_sample1 = up_conv(extend, 2, 64*8)\n",
    "concat1 = cropping_concat(encoding_out=conv_4_output, decoding_out=up_sample1)\n",
    "print(\"concat_1 : \", concat1)\n",
    "#5 conv and conv\n",
    "conv_5_output = conv_step(concat1, 3, 64*4)\n",
    "print(\"5_conv_layer_test : \", conv_5_output)\n",
    "\n",
    "#upsample and concat\n",
    "up_sample2 = up_conv(conv_5_output, 2, 64*4)\n",
    "concat2 = cropping_concat(encoding_out=conv_3_output, decoding_out=up_sample2)\n",
    "print(\"concat_2 : \", concat2)\n",
    "#5 conv and conv\n",
    "conv_6_output = conv_step(concat2, 3, 64*2)\n",
    "print(\"6_conv_layer_test : \", conv_6_output)\n",
    "\n",
    "#upsample and concat\n",
    "up_sample3 = up_conv(conv_6_output, 2, 64*2)\n",
    "concat3 = cropping_concat(encoding_out=conv_2_output, decoding_out=up_sample3)\n",
    "print(\"concat_3 : \", concat3)\n",
    "#5 conv and conv\n",
    "conv_7_output = conv_step(concat3, 3, 64)\n",
    "print(\"7_conv_layer_test : \", conv_6_output)\n",
    "\n",
    "#upsample and concat\n",
    "up_sample4 = up_conv(conv_7_output, 2, 64)\n",
    "concat4 = cropping_concat(encoding_out=conv_1_output, decoding_out=up_sample4)\n",
    "print(\"concat_4 : \", concat4)\n",
    "#5 conv and conv\n",
    "conv_8_output = conv_step(concat4, 3, 64)\n",
    "print(\"8_conv_layer_test : \", conv_8_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segmentation\n",
    "#segmentation = conv_step(conv_8_output, 1, 2)\n",
    "#print(\"segmentation : \", segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tf.decode_raw(\n",
    "    bytes,\n",
    "    out_type,\n",
    "    little_endian=True,\n",
    "    name=None\n",
    ")\n",
    "'''\n",
    "image_tensor = None\n",
    "with open(\"./dataset/0002/Chevron_000045.jpg\",'rb') as fp:\n",
    "    image_tensor = tf.decode_raw(fp.read(), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"DecodeRaw:0\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.47486124e+20  1.29320000e+04  2.35603141e-38  2.35098898e-38\n",
      "  3.58732407e-43  1.28859360e+02  2.52084764e-35  4.00303168e-34\n",
      "  1.62533381e-33  1.06335513e-31  2.69728581e-32  4.82931315e-28\n",
      "  1.95954301e-21  2.09272050e-21  1.32230120e-19  1.41607169e-19\n",
      "  5.39892163e-22  4.06689520e-14  1.65019344e-07  2.20939820e-15\n",
      "  1.07241300e-08  1.66874941e-07  2.02035205e-38  1.64913684e-33\n",
      "  1.07117922e-31  1.82304335e-24  5.28987895e-19  1.03723767e-08\n",
      "  1.03723767e-08  1.03723767e-08  1.03723767e-08  1.03723767e-08\n",
      "  1.03723767e-08  1.03723767e-08  1.03723767e-08  1.03723767e-08\n",
      "  1.03723767e-08  1.03723767e-08  1.03723767e-08 -7.97487736e+00\n",
      "  7.40782420e-40  5.64240158e-37  9.41371345e-38  1.03344065e-28\n",
      "  1.80912354e-38  2.35099739e-38  2.36942895e-38  9.21956299e-41\n",
      "  0.00000000e+00  2.35098870e-38  6.20716262e-36  1.63737069e-33\n",
      " -2.04034497e+03  1.53429850e-39  3.84985969e-37  6.16032652e-36\n",
      "  3.68783921e-40  4.64694785e-38  1.50477088e-36  4.94734295e-19\n",
      "  1.69453197e-27  1.83474305e-18 -3.27081026e-38  7.40678779e-18\n",
      "  7.82317427e-26  1.04438011e-16 -1.78075338e-37  4.84802802e-25\n",
      "  1.33658729e-16  3.73374495e-14  2.70014652e-06  7.06556661e-04\n",
      "  1.26250654e+04  3.29780975e+06  5.86395366e+13  1.52943002e+16\n",
      "  2.70818433e+23  7.05431855e+25  1.24460410e+33  3.23831309e+35\n",
      " -5.02237480e-35 -1.32439760e-32 -6.00095489e-26 -1.57776567e-23\n",
      " -7.09654394e-17 -1.86129951e-14 -8.31981382e-08 -2.17807028e-05\n",
      " -9.33627319e+01 -2.53143809e+04 -6.61206750e+06 -2.92507783e+13\n",
      " -7.62948864e+15 -8.37047696e+21 -2.18077005e+24 -2.32647256e+30\n",
      " -6.21029410e+32 -1.61589858e+35  1.80915843e-38  3.76171062e-37\n",
      "  2.36942783e-38  2.36942783e-38  1.40129846e-45  2.35098870e-38\n",
      "  6.20716262e-36  1.63737069e-33 -2.04034497e+03  1.62613400e-39\n",
      "  1.52818893e-36  9.93146249e-35  3.68783921e-40  1.09291429e-38\n",
      "  1.03346954e-28  2.34314346e-09  5.18269420e+10  3.04663147e-27\n",
      "  7.77569126e-34 -9.84307292e-19  7.46780063e-18  9.70649155e-26\n",
      "  2.01689940e-32 -2.07688387e+20  1.96380395e-24  2.30512753e-15\n",
      "  6.33898253e-07  1.75681751e-04  3.14020166e+03  8.20340375e+05\n",
      "  1.45908868e+13  3.80591387e+15  6.74082669e+22  1.75599422e+25\n",
      "  3.09878249e+32  8.06320360e+34 -3.09177758e-36 -8.15664234e-34\n",
      " -3.69921877e-27 -9.73128163e-25 -4.19044073e-18 -1.14937998e-15\n",
      " -3.01374567e-13 -1.34633433e-06 -3.52320902e-04 -1.56608521e+03\n",
      " -4.09142156e+05 -1.81069061e+12 -4.72427746e+14 -2.01854375e+21\n",
      " -5.42822070e+23 -1.41389783e+26 -6.21029410e+32 -1.61589858e+35\n",
      "  2.01119653e-38  9.29285090e-41  1.03393188e-28 -1.11235755e-16\n",
      "  1.25541568e-34 -7.66327739e+25 -6.64509527e-21 -2.62273615e-03\n",
      "  3.26892110e-28  1.34747672e-17 -2.29746906e+16 -7.78359066e-09\n",
      " -1.85862506e-11 -4.13614837e-10  4.41139415e-02  5.52431679e-17\n",
      " -4.58646393e-25 -3.36695449e+23  1.77139800e+06 -7.82529357e+12\n",
      "  6.32885182e+19  3.12380310e-22 -3.98889222e+11 -1.31019982e+14\n",
      "  2.20852539e+34 -4.25905604e+24  8.11901807e-25  3.74740765e+27\n",
      "  1.05886645e+37 -1.89153098e-35  6.49808855e+10 -5.84432422e-31\n",
      "  1.26335865e+20 -1.39428844e+05 -5.37086951e+11 -1.07035690e+07\n",
      "  5.68985495e-27  3.30313350e+16  2.24858254e+27 -2.36053680e+38\n",
      " -1.58952712e-14 -7.49650486e+34  6.95293726e+19  2.27812689e+33\n",
      " -3.25325334e+35  1.08748397e-08  2.77268555e-24 -4.00277376e-02\n",
      " -4.20575357e+29 -2.86344765e+10  7.94458620e+32  2.87219288e+28\n",
      "  6.73394651e+29 -4.95365421e+33 -3.21230418e+21  4.53604256e+26\n",
      "  1.92253349e-11 -5.72328033e+23  7.08147990e-22 -7.36185468e-09\n",
      " -8.13471040e+08 -8.94815100e+36  2.74928320e+32  7.84931318e+26\n",
      " -3.20800979e+30 -5.86447620e+37  2.26915424e-13  1.00752731e+35\n",
      " -1.21907810e-37  3.12401421e+21  1.25636412e-09 -6.58491305e-32\n",
      "  2.16081146e-12  3.31513377e-08  1.87931101e-17 -1.29810393e+29\n",
      "  1.05474258e+02  1.12150474e-21  4.08807357e+31 -1.19915434e+13\n",
      "  1.13940583e+34  4.31682556e-20 -8.90898516e-36  3.90478027e+02\n",
      " -2.57613152e+08 -9.76327585e+16 -6.16812492e-20  5.29625038e-20\n",
      " -5.54428168e-24 -2.09778234e+20  7.10751513e+33  2.50195767e+32\n",
      " -7.69100220e+02  2.40490820e+03 -2.11190404e+33 -5.30845362e+32\n",
      " -1.43939314e+01 -6.36056657e+19  1.45244712e+35  4.61307216e+11\n",
      "  8.42963770e+03  2.01934156e+05 -1.55221787e-04  1.04055699e+09\n",
      " -7.12851302e+09 -1.51783506e+34 -1.13010717e+20 -2.68410492e+19\n",
      " -4.74241174e-18  4.37919253e-33 -1.50018090e+35 -5.40842217e-17\n",
      " -7.33125941e+22  1.10685770e+27 -2.13061357e-29 -7.11625644e+36\n",
      " -1.02816902e-01  5.62353479e-27 -4.91252065e+18 -2.70456044e+37\n",
      "  2.08265377e-16  7.91359290e+29 -1.21113100e+06  4.05596154e+30\n",
      "  2.10027878e+02 -1.38817563e-20 -2.79630780e-11  8.03975972e-13\n",
      "  5.51523583e-04 -2.14917836e-34  3.27729648e+16  1.67809639e-38\n",
      " -2.74725391e-33 -4.53599712e+21  1.79153150e+24  4.12690861e-06\n",
      " -3.60589946e-16  2.89350156e+04 -7.37650283e+20  1.82071076e+32\n",
      "  9.18555241e+17 -3.38086318e+27 -6.00286150e+06  1.31923717e-03\n",
      " -9.67161355e-13  1.93373771e-16  6.60841673e+18 -2.73417582e-18\n",
      " -2.62910525e-38  5.72183881e+20 -3.22216864e-10  8.22800639e+27\n",
      " -8.06694198e-03  7.19210354e-25  1.41306406e-33  4.26327999e-21\n",
      "  5.15265229e-34 -5.12224616e+21 -5.21372581e+20  2.17289980e-05\n",
      "  1.27533594e+05  1.43428629e+17 -1.06382377e-01 -7.24349578e-04\n",
      "  1.02309922e+26  4.05768555e+04 -2.94854608e+21  1.31730829e+09\n",
      "  3.37506276e-06 -4.28752208e-39 -9.56162988e+37  7.96800884e+21\n",
      "  1.77246472e-14  2.51055913e-18  3.85160734e+12  3.50656738e+02\n",
      "  5.26428826e+37 -1.43988876e+21  3.87205034e-01 -4.89541609e+32\n",
      " -5.55318093e+31 -4.52891708e-33 -1.50935986e-14 -7.62631228e+34\n",
      " -8.94834167e-38 -5.76502912e+08  9.56302570e+13  1.73478576e-21\n",
      " -1.15685439e+22  1.04966131e+19 -3.68858650e+09 -7.55166429e-32\n",
      "  1.08764245e-28 -7.53352416e-20 -3.63958410e-19  5.87048586e-21\n",
      "  1.01233162e-31 -2.34596291e+32 -8.97306608e+15]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(image_tensor) #execute init_op\n",
    "    #print the random values that we sample\n",
    "    print (sess.run(image_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
